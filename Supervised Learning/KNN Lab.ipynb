{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"KNN Lab.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"NRqdXHq2BaQJ"},"source":["## KNN Regressor\n","\n","As discussed in our lecture, we are now all familiar with the **KNN** for the classification algorithm.\n","\n","Interestingly, **KNN** can be used for regression as well and during this exercise, you will know some concepts around it. Also, we will talk about some implementational details when needed alongside our workflow. \n","\n","### Idea \n","The idea of KNN Regressor is very simple, just find the most similar data points and take the average of them all.\n","\n","### Dataset\n","We will be working with the **NBA** dataset. A dataset for the NBA competition for basketball. Our goal will be to find the possible points scored (**pts**) by each player based on some statistics measured for every one of them.\n","\n","### Training\n","Interestingly, **KNN** can be used for regression as well and during this exercise, you will know some concepts around it. Also, we will talk about some implementational details when needed alongside our workflow. \n","\n","### Evaluation Metric\n","R-squared\n","\n","### Implementation Skills\n","1. Imputation\n","2. Grid Search\n","3. ML Pipeline.\n"]},{"cell_type":"markdown","metadata":{"id":"xIzJBx-PBaQL"},"source":["#### Importing and reading the dataset\n","\n","In the following few cells, import and read the **nba_2013.csv** file from the **data** folder. Try to view some of it's data, shape, Nulls, total number of rows and colums etc.. "]},{"cell_type":"markdown","metadata":{"id":"r5bDEGvVBaQM"},"source":["The first step has been done for you."]},{"cell_type":"code","metadata":{"id":"iaQYpwgkBaQM","outputId":"09598464-d10e-426e-b8f6-b50cca8abeb8"},"source":["# Import the data\n","import pandas as pd\n","nba = pd.read_csv('data/nba_2013.csv')\n","# Read the data head\n","nba.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>player</th>\n","      <th>pos</th>\n","      <th>age</th>\n","      <th>bref_team_id</th>\n","      <th>g</th>\n","      <th>gs</th>\n","      <th>mp</th>\n","      <th>fg</th>\n","      <th>fga</th>\n","      <th>fg.</th>\n","      <th>...</th>\n","      <th>drb</th>\n","      <th>trb</th>\n","      <th>ast</th>\n","      <th>stl</th>\n","      <th>blk</th>\n","      <th>tov</th>\n","      <th>pf</th>\n","      <th>pts</th>\n","      <th>season</th>\n","      <th>season_end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Quincy Acy</td>\n","      <td>SF</td>\n","      <td>23</td>\n","      <td>TOT</td>\n","      <td>63</td>\n","      <td>0</td>\n","      <td>847</td>\n","      <td>66</td>\n","      <td>141</td>\n","      <td>0.468</td>\n","      <td>...</td>\n","      <td>144</td>\n","      <td>216</td>\n","      <td>28</td>\n","      <td>23</td>\n","      <td>26</td>\n","      <td>30</td>\n","      <td>122</td>\n","      <td>171</td>\n","      <td>2013-2014</td>\n","      <td>2013</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Steven Adams</td>\n","      <td>C</td>\n","      <td>20</td>\n","      <td>OKC</td>\n","      <td>81</td>\n","      <td>20</td>\n","      <td>1197</td>\n","      <td>93</td>\n","      <td>185</td>\n","      <td>0.503</td>\n","      <td>...</td>\n","      <td>190</td>\n","      <td>332</td>\n","      <td>43</td>\n","      <td>40</td>\n","      <td>57</td>\n","      <td>71</td>\n","      <td>203</td>\n","      <td>265</td>\n","      <td>2013-2014</td>\n","      <td>2013</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Jeff Adrien</td>\n","      <td>PF</td>\n","      <td>27</td>\n","      <td>TOT</td>\n","      <td>53</td>\n","      <td>12</td>\n","      <td>961</td>\n","      <td>143</td>\n","      <td>275</td>\n","      <td>0.520</td>\n","      <td>...</td>\n","      <td>204</td>\n","      <td>306</td>\n","      <td>38</td>\n","      <td>24</td>\n","      <td>36</td>\n","      <td>39</td>\n","      <td>108</td>\n","      <td>362</td>\n","      <td>2013-2014</td>\n","      <td>2013</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Arron Afflalo</td>\n","      <td>SG</td>\n","      <td>28</td>\n","      <td>ORL</td>\n","      <td>73</td>\n","      <td>73</td>\n","      <td>2552</td>\n","      <td>464</td>\n","      <td>1011</td>\n","      <td>0.459</td>\n","      <td>...</td>\n","      <td>230</td>\n","      <td>262</td>\n","      <td>248</td>\n","      <td>35</td>\n","      <td>3</td>\n","      <td>146</td>\n","      <td>136</td>\n","      <td>1330</td>\n","      <td>2013-2014</td>\n","      <td>2013</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Alexis Ajinca</td>\n","      <td>C</td>\n","      <td>25</td>\n","      <td>NOP</td>\n","      <td>56</td>\n","      <td>30</td>\n","      <td>951</td>\n","      <td>136</td>\n","      <td>249</td>\n","      <td>0.546</td>\n","      <td>...</td>\n","      <td>183</td>\n","      <td>277</td>\n","      <td>40</td>\n","      <td>23</td>\n","      <td>46</td>\n","      <td>63</td>\n","      <td>187</td>\n","      <td>328</td>\n","      <td>2013-2014</td>\n","      <td>2013</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 31 columns</p>\n","</div>"],"text/plain":["          player pos  age bref_team_id   g  gs    mp   fg   fga    fg.  ...  \\\n","0     Quincy Acy  SF   23          TOT  63   0   847   66   141  0.468  ...   \n","1   Steven Adams   C   20          OKC  81  20  1197   93   185  0.503  ...   \n","2    Jeff Adrien  PF   27          TOT  53  12   961  143   275  0.520  ...   \n","3  Arron Afflalo  SG   28          ORL  73  73  2552  464  1011  0.459  ...   \n","4  Alexis Ajinca   C   25          NOP  56  30   951  136   249  0.546  ...   \n","\n","   drb  trb  ast  stl  blk  tov   pf   pts     season  season_end  \n","0  144  216   28   23   26   30  122   171  2013-2014        2013  \n","1  190  332   43   40   57   71  203   265  2013-2014        2013  \n","2  204  306   38   24   36   39  108   362  2013-2014        2013  \n","3  230  262  248   35    3  146  136  1330  2013-2014        2013  \n","4  183  277   40   23   46   63  187   328  2013-2014        2013  \n","\n","[5 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"o29kppr_BaQN"},"source":["View column names, dimentions, and Nulls count."]},{"cell_type":"code","metadata":{"id":"heBGOVryBaQN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLI4PDYNBaQO"},"source":["It may be also a good point to see some of statstics about columns."]},{"cell_type":"code","metadata":{"id":"JMcXA87tBaQO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EXTmg2ZcBaQO"},"source":["### Preprocessing\n","\n","So, our preprocessing will be constructed of three main parts listed as follows:\n","1. **Removing unnecessary columns and data splitting**\n","\n","    You may have noticed the existence of several columns that holds categorical data. Hence, we are handling a regression problem, you can assume these will be of the least importance and remove them then, we will .\n","    \n","    \n","2. **Imputation**\n","\n","    You should also have noticed that we have a missing data problem. Hence, our data is not big enough, removing them will not be so good. so, we will impute this value with any statistical approximation measure such as mean or median ( Hint: You can use the mean as it will be the simplest.\n","    \n","3. **Scaling**\n","\n","    You may have noticed the existence of several columns that holds categorical data. Hence, we are handling a regression problem, you can assume these will be of the least importance and remove them..* or **StandardScaler** but for KNN especially, we prefer **MinMaxSaler**. Do you know **Why**?\n","    \n","    \n","\n","When applying these concepts we will adopt the sklearn implementations as they are much more organized and robust to changes and will be grouped together as a one full pipeline. Let's start!"]},{"cell_type":"markdown","metadata":{"id":"aPfP6kqTBaQP"},"source":["#### Removing unnecessary columns and data splitting\n","\n","Try to find the categorical columns and remove them then split the data into predictors and target. After this, split the data into train and test chuncks. The below import statement could be helpful for you. \n"]},{"cell_type":"code","metadata":{"id":"Z7O9_VhPBaQP"},"source":["# Import train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","# Remove unnessary columns\n","\n","\n","\n","# Split into target and predictors\n","\n","\n","\n","\n","# Split with 75% for training and 25% for testing respectively.\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qJALfPElBaQP"},"source":["### Imputation\n","\n","Use the sklearn implementation **SimpleImputer**. The import statement below may help you. \n","\n","**Hint**: search for the documentation to know how **SimpleImputer** works."]},{"cell_type":"code","metadata":{"id":"AlRN3LXcBaQQ"},"source":["# Import simple Imputer\n","from sklearn.impute import SimpleImputer\n","\n","\n","# Instantiate SimpleImputer Instance\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77zDvUXZBaQQ"},"source":["### Scaling\n","\n","Use the sklearn implementation **MinMaxScaler**. The import statement below may help you. \n","\n","**Hint**: search for the documentation to know how **MinMaxScaler** works.\n"]},{"cell_type":"code","metadata":{"id":"rh7BourXBaQQ"},"source":["# Import MinMaxScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","# Instantiate MinMaxScaler Instance\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8U42aOhBaQQ"},"source":["### Modeling\n","\n","Now, as we finished the preprocessing by now we will now go to the modeling part.\n","\n","Note that: We will not fit any of these classes right now and the model as well. We will wait to fit the overall pipeline and as usual, the import statement will be done for you"]},{"cell_type":"code","metadata":{"id":"Uw2-CYElBaQR"},"source":["# Import KNeighborsRegressor \n","from sklearn.neighbors import KNeighborsRegressor\n","\n","\n","# Now, instantiate a model instance (n_neighbors = 3)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPMatWR-BaQR"},"source":["### Pipeline\n","\n","Now, let's combine all these steps into a full pipeline. all the steps should be ordered logically. The import statement will be done for you. "]},{"cell_type":"code","metadata":{"id":"SIfwovlVBaQR"},"source":["# Import pipeline\n","from sklearn.pipeline import Pipeline\n","\n","# Let's organize a list of tuble with the required steps\n","\n","steps = [(),                                                  # Add the imputation here\n","         (),                                                  # Add the scaling here\n","         ()]                                                  # Add the model here\n","\n","\n","# Instantiate the Pipeline instance\n","\n","\n","# Fit the pipeline into the training data\n","\n","\n","# Get predictions for the testing data \n","\n","\n","# Evaluate your model using R-squared (Will import it for you)\n","from sklearn.metrics import r2_score\n","\n","\n","# Print the R-squared for the testing data\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uwCvsIcJBaQR"},"source":["### Hyperparameter Tuning\n","\n","As you may have noticed, there are several hyperparameters in the pipeline we created such as the number of neighbors or the distance measure.\n","One of the easiest and quickest ways in deciding the best hyper paramenters. Now, you will try to tune the following:\n","    -  n_neighbors\n","    -  distance measure ( choose between cosine, manhattan , or euclidean )\n","    \n","    \n","GridSearch will be imported for you.\n","    "]},{"cell_type":"code","metadata":{"id":"HmO5VDejBaQS"},"source":["# Import GridSearch\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","\n","\n","# Create the parameters dictionary. (You may need to check the documentations to know about it)\n","\n","\n","\n","# Instantiate a GridSearch instance (Note : make CV=5)\n","\n","\n","\n","# Print the best hyperparameters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G21PqD1KBaQS"},"source":["## Thanks and all the best"]}]}